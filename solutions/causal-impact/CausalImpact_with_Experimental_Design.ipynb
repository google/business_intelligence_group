{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google/business_intelligence_group/blob/development/solutions/causal-impact/CausalImpact_with_Experimental_Design.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH_QXijHFzJP"
      },
      "source": [
        "# **CausalImpact with Experimental Design**\n",
        "\n",
        "This Colab file contains *Experimental Design* and *CausalImpact Analysis*.\n",
        "\n",
        "See [README.md](https://github.com/google/business_intelligence_group/tree/main/solutions/causal-impact) for details\n",
        "\n",
        "---\n",
        "\n",
        "Copyright 2024 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step.1 (~ 2min)\n",
        "%%time\n",
        "\n",
        "import sys\n",
        "if 'fastdtw' not in sys.modules:\n",
        "  !pip install 'fastdtw' --q\n",
        "if 'tslearn' not in sys.modules:\n",
        "  !pip install 'tslearn' --q\n",
        "if 'tfp-causalimpact' not in sys.modules:\n",
        "  !pip install 'tfp-causalimpact' --q\n",
        "\n",
        "# Data Load\n",
        "from google.colab import auth, files, widgets\n",
        "from google.auth import default\n",
        "from google.cloud import bigquery\n",
        "import io\n",
        "import os\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Calculate\n",
        "import altair as alt\n",
        "import itertools\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import fastdtw\n",
        "\n",
        "from tslearn.clustering import TimeSeriesKMeans\n",
        "from decimal import Decimal, ROUND_HALF_UP\n",
        "from scipy.spatial.distance import euclidean\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from statsmodels.tsa.seasonal import STL\n",
        "\n",
        "# UI/UX\n",
        "import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import ipywidgets\n",
        "from IPython.display import display, Markdown, HTML, Javascript\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# causalimpact\n",
        "import causalimpact\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "\n",
        "class PreProcess(object):\n",
        "  \"\"\"PreProcess handles process from data loading to visualization.\n",
        "\n",
        "    Create a UI, load time series data based on input and do some\n",
        "    transformations to pass it to analysis. This also includes visualization of\n",
        "    points that should be confirmed in time series data.\n",
        "\n",
        "    Attributes:\n",
        "      _apply_text_style: Decorate the text\n",
        "      define_ui: Define the UI using ipywidget\n",
        "      generate_ui: Generates UI for input from the user\n",
        "      load_data: Load data from any data source\n",
        "      _load_data_from_sheet: Load data from spreadsheet\n",
        "      _load_data_from_csv: Load data from CSV\n",
        "      _load_data_from_bigquery: Load data from Big Query\n",
        "      format_date: Set index\n",
        "      _shape_wide: Configure narrow/wide conversion\n",
        "      _trend_check: Visualize data\n",
        "      saving_params: Save the contents entered in the UI\n",
        "      set_params: Set the saved input contents to the instance\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.define_ui()\n",
        "\n",
        "  @staticmethod\n",
        "  def _apply_text_style(type, text):\n",
        "    if type == 'success':\n",
        "      return print(f\"\\033[38;2;15;157;88m \" + text + \"\\033[0m\")\n",
        "\n",
        "    if type == 'failure':\n",
        "      return print(f\"\\033[38;2;219;68;55m \" + text + \"\\033[0m\")\n",
        "\n",
        "    if isinstance(type, int):\n",
        "      span_style = ipywidgets.HTML(\n",
        "        \"<span style='font-size:\" + str(type) + \"px; background: \"\n",
        "        \"linear-gradient(transparent 90%, #4285F4 0%);'>\"\n",
        "        + text\n",
        "        + '</style>'\n",
        "      )\n",
        "      return span_style\n",
        "\n",
        "  def define_ui(self):\n",
        "    self._define_data_source_widgets()\n",
        "    self._define_data_format_widgets()\n",
        "    self._define_date_widgets()\n",
        "    self._define_experimental_design_widgets()\n",
        "    self._define_simulation_widgets()\n",
        "\n",
        "  def _define_data_source_widgets(self):\n",
        "    # Input box for data sources\n",
        "    self.sheet_url = ipywidgets.Text(\n",
        "        placeholder='Please enter google spreadsheet url',\n",
        "        value='https://docs.google.com/spreadsheets/d/1dISrbX1mZHgzpsIct2QXFOWWRRJiCxDSmSzjuZz64Tw/edit#gid=0',\n",
        "        description='spreadsheet url:',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout=ipywidgets.Layout(width='800px'),\n",
        "    )\n",
        "    self.sheet_name = ipywidgets.Text(\n",
        "        placeholder='Please enter sheet name',\n",
        "        value='analysis_data',\n",
        "        # value='raw_data',\n",
        "        description='sheet name:',\n",
        "    )\n",
        "    self.csv_name = ipywidgets.Text(\n",
        "        placeholder='Please enter csv name',\n",
        "        description='csv name:',\n",
        "        layout=ipywidgets.Layout(width='500px'),\n",
        "    )\n",
        "    self.bq_project_id = ipywidgets.Text(\n",
        "        placeholder='Please enter project id',\n",
        "        description='project id:',\n",
        "        layout=ipywidgets.Layout(width='500px'),\n",
        "    )\n",
        "    self.bq_table_name = ipywidgets.Text(\n",
        "        placeholder='Please enter table name',\n",
        "        description='table name:',\n",
        "        layout=ipywidgets.Layout(width='500px'),\n",
        "    )\n",
        "\n",
        "  def _define_data_format_widgets(self):\n",
        "    # Input box for data format\n",
        "    self.date_col = ipywidgets.Text(\n",
        "        placeholder='Please enter date column name',\n",
        "        value='Date',\n",
        "        description='date column:',\n",
        "    )\n",
        "    self.pivot_col = ipywidgets.Text(\n",
        "        placeholder='Please enter pivot column name',\n",
        "        value='Geo',\n",
        "        description='pivot column:',\n",
        "    )\n",
        "    self.kpi_col = ipywidgets.Text(\n",
        "        placeholder='Please enter kpi column name',\n",
        "        value='KPI',\n",
        "        description='kpi column:',\n",
        "    )\n",
        "\n",
        "  def _define_experimental_design_widgets(self):\n",
        "    # Input box for Experimental_Design-related\n",
        "    self.exclude_cols = ipywidgets.Text(\n",
        "        placeholder=(\n",
        "            'Enter comma-separated columns if any columns are not used in the'\n",
        "            ' design.'\n",
        "        ),\n",
        "        description='exclude cols:',\n",
        "        layout=ipywidgets.Layout(width='1000px'),\n",
        "    )\n",
        "    self.num_of_split = ipywidgets.Dropdown(\n",
        "        options=[2, 3, 4, 5],\n",
        "        value=2,\n",
        "        description='split#:',\n",
        "        disabled=False,\n",
        "    )\n",
        "    self.target_columns = ipywidgets.Text(\n",
        "        placeholder='Please enter comma-separated entries',\n",
        "        value='Tokyo, Kanagawa',\n",
        "        description='target_cols:',\n",
        "        layout=ipywidgets.Layout(width='500px'),\n",
        "    )\n",
        "    self.num_of_pick_range = ipywidgets.IntRangeSlider(\n",
        "        value=[5, 10],\n",
        "        min=1,\n",
        "        max=50,\n",
        "        step=1,\n",
        "        description='pick range:',\n",
        "        orientation='horizontal',\n",
        "        readout=True,\n",
        "        readout_format='d',\n",
        "    )\n",
        "    self.num_of_covariate = ipywidgets.Dropdown(\n",
        "        options=[1, 2, 3, 4, 5],\n",
        "        value=1,\n",
        "        description='covariate#:',\n",
        "        layout=ipywidgets.Layout(width='192px'),\n",
        "    )\n",
        "    self.target_share = ipywidgets.FloatSlider(\n",
        "        value=0.3,\n",
        "        min=0.05,\n",
        "        max=0.5,\n",
        "        step=0.05,\n",
        "        description='target share#:',\n",
        "        orientation='horizontal',\n",
        "        readout=True,\n",
        "        readout_format='.1%',\n",
        "    )\n",
        "    self.control_columns = ipywidgets.Text(\n",
        "        placeholder='Please enter comma-separated entries',\n",
        "        value='Aomori, Akita',\n",
        "        description='control_cols:',\n",
        "        layout=ipywidgets.Layout(width='500px'),\n",
        "    )\n",
        "\n",
        "  def _define_simulation_widgets(self):\n",
        "    # Input box for simulation params\n",
        "    self.num_of_seasons = ipywidgets.IntText(\n",
        "        value=1,\n",
        "        description='num_of_seasons:',\n",
        "        disabled=False,\n",
        "        style={'description_width': 'initial'},\n",
        "    )\n",
        "    self.estimate_icpa = ipywidgets.IntText(\n",
        "        value=1000,\n",
        "        description='Estimated iCPA:',\n",
        "        style={'description_width': 'initial'},\n",
        "    )\n",
        "    self.credible_interval = ipywidgets.RadioButtons(\n",
        "        options=[70, 80, 90, 95],\n",
        "        value=90,\n",
        "        description='Credible interval %:',\n",
        "        style={'description_width': 'initial'},\n",
        "    )\n",
        "\n",
        "  def _define_date_widgets(self):\n",
        "    # Input box for Date-related\n",
        "    self.pre_period_start = ipywidgets.DatePicker(\n",
        "        description='Pre Start:',\n",
        "        value=datetime.date.today() - relativedelta(days=122),\n",
        "    )\n",
        "    self.pre_period_end = ipywidgets.DatePicker(\n",
        "        description='Pre End:',\n",
        "        value=datetime.date.today() - relativedelta(days=32),\n",
        "    )\n",
        "    self.post_period_start = ipywidgets.DatePicker(\n",
        "        description='Post Start:',\n",
        "        value=datetime.date.today() - relativedelta(days=31),\n",
        "    )\n",
        "    self.post_period_end = ipywidgets.DatePicker(\n",
        "        description='Post End:',\n",
        "        value=datetime.date.today(),\n",
        "    )\n",
        "    self.start_date = ipywidgets.DatePicker(\n",
        "        description='Start Date:',\n",
        "        value=datetime.date.today() - relativedelta(days=122),\n",
        "    )\n",
        "    self.end_date = ipywidgets.DatePicker(\n",
        "        description='End Date:',\n",
        "        value=datetime.date.today() - relativedelta(days=32),\n",
        "    )\n",
        "    self.depend_data = ipywidgets.ToggleButton(\n",
        "        value=False,\n",
        "        description='Click >> Use the beginning and end of data',\n",
        "        disabled=False,\n",
        "        button_style='info',\n",
        "        tooltip='Description',\n",
        "        layout=ipywidgets.Layout(width='300px'),\n",
        "    )\n",
        "\n",
        "  def generate_ui(self):\n",
        "    self._build_source_selection_tab()\n",
        "    self._build_data_type_selection_tab()\n",
        "    self._build_design_type_tab()\n",
        "    self._build_purpose_selection_tab()\n",
        "\n",
        "  def _build_source_selection_tab(self):\n",
        "    # UI for data soure\n",
        "    self.soure_selection = ipywidgets.Tab()\n",
        "    self.soure_selection.children = [\n",
        "        ipywidgets.VBox([self.sheet_url, self.sheet_name]),\n",
        "        ipywidgets.VBox([self.csv_name]),\n",
        "        ipywidgets.VBox([self.bq_project_id, self.bq_table_name]),\n",
        "    ]\n",
        "    self.soure_selection.set_title(0, 'Google_Spreadsheet')\n",
        "    self.soure_selection.set_title(1, 'CSV_file')\n",
        "    self.soure_selection.set_title(2, 'Big_Query')\n",
        "\n",
        "  def _build_data_type_selection_tab(self):\n",
        "    # UI for data type(narrow or wide)\n",
        "    self.data_type_selection = ipywidgets.Tab()\n",
        "    self.data_type_selection.children = [\n",
        "        ipywidgets.VBox([\n",
        "            ipywidgets.Label(\n",
        "                'Wide, or unstacked data is presented with each different'\n",
        "                ' data variable in a separate column.'\n",
        "            ),\n",
        "            self.date_col,\n",
        "        ]),\n",
        "        ipywidgets.VBox([\n",
        "            ipywidgets.Label(\n",
        "                'Narrow, stacked, or long data is presented with one column '\n",
        "                'containing all the values and another column listing the '\n",
        "                'context of the value'\n",
        "            ),\n",
        "            ipywidgets.HBox([self.date_col, self.pivot_col, self.kpi_col]),\n",
        "        ]),\n",
        "    ]\n",
        "    self.data_type_selection.set_title(0, 'Wide_Format')\n",
        "    self.data_type_selection.set_title(1, 'Narrow_Format')\n",
        "\n",
        "  def _build_design_type_tab(self):\n",
        "    # UI for experimental design\n",
        "    self.design_type = ipywidgets.Tab(\n",
        "        children=[\n",
        "            ipywidgets.VBox([\n",
        "                ipywidgets.HTML(\n",
        "                    'divide_equally divides the time series data into N'\n",
        "                    ' groups(split#) with similar movements.'\n",
        "                ),\n",
        "                self.num_of_split,\n",
        "                self.exclude_cols,\n",
        "            ]),\n",
        "            ipywidgets.VBox([\n",
        "                ipywidgets.HTML(\n",
        "                    'similarity_selection extracts N groups(covariate#) that '\n",
        "                    'move similarly to particular columns(target_cols).'\n",
        "                ),\n",
        "                ipywidgets.HBox([\n",
        "                    self.target_columns,\n",
        "                    self.num_of_covariate,\n",
        "                    self.num_of_pick_range,\n",
        "                ]),\n",
        "                self.exclude_cols,\n",
        "            ]),\n",
        "            ipywidgets.VBox([\n",
        "                ipywidgets.HTML(\n",
        "                    'target share extracts targeted time series data from'\n",
        "                    ' the proportion of interventions.'\n",
        "                ),\n",
        "                self.target_share,\n",
        "                self.exclude_cols,\n",
        "            ]),\n",
        "            ipywidgets.VBox([\n",
        "                ipywidgets.HTML(\n",
        "                    'To improve reproducibility, it is important to create an'\n",
        "                    ' accurate counterfactual model rather than a balanced'\n",
        "                    ' assignment.'\n",
        "                ),\n",
        "                self.target_columns,\n",
        "                self.control_columns,\n",
        "            ]),\n",
        "        ]\n",
        "    )\n",
        "    self.design_type.set_title(0, 'A: divide_equally')\n",
        "    self.design_type.set_title(1, 'B: similarity_selection')\n",
        "    self.design_type.set_title(2, 'C: target_share')\n",
        "    self.design_type.set_title(3, 'D: pre-allocated')\n",
        "\n",
        "  def _build_purpose_selection_tab(self):\n",
        "    # UI for purpose (CausalImpact or Experimental Design)\n",
        "    self.purpose_selection = ipywidgets.Tab()\n",
        "    self.date_selection = ipywidgets.Tab()\n",
        "    self.date_selection.children = [\n",
        "        ipywidgets.VBox(\n",
        "            [\n",
        "                ipywidgets.HTML('The <b>minimum</b> date of the data is '\n",
        "                'selected as the start date.'),\n",
        "                ipywidgets.HTML('The <b>maximum</b> date in the data is '\n",
        "                'selected as the end date.'),\n",
        "            ]),\n",
        "        ipywidgets.VBox(\n",
        "            [\n",
        "                self.start_date,\n",
        "                self.end_date,\n",
        "            ]\n",
        "        )]\n",
        "    self.date_selection.set_title(0, 'automatic selection')\n",
        "    self.date_selection.set_title(1, 'manual input')\n",
        "\n",
        "    self.purpose_selection.children = [\n",
        "        # Causalimpact\n",
        "        ipywidgets.VBox([\n",
        "            PreProcess._apply_text_style(\n",
        "                15, '⑶ - a: Enter the Pre and Post the intervention.'\n",
        "            ),\n",
        "            self.pre_period_start,\n",
        "            self.pre_period_end,\n",
        "            self.post_period_start,\n",
        "            self.post_period_end,\n",
        "            PreProcess._apply_text_style(\n",
        "                15,\n",
        "                '⑶ - b: Enter the number of periodicities in the'\n",
        "                ' time series data.(default=1)',\n",
        "            ),\n",
        "            ipywidgets.VBox([self.num_of_seasons, self.credible_interval]),\n",
        "        ]),\n",
        "        # Experimental_Design\n",
        "        ipywidgets.VBox([\n",
        "            PreProcess._apply_text_style(\n",
        "                15,\n",
        "                '⑶ - a: Please select date for experimental design',\n",
        "            ),\n",
        "            self.date_selection,\n",
        "            PreProcess._apply_text_style(\n",
        "                15,\n",
        "                '⑶ - b: Select the <b>experimental design method</b> and'\n",
        "                ' enter the necessary items.',\n",
        "            ),\n",
        "            self.design_type,\n",
        "            PreProcess._apply_text_style(\n",
        "                15,\n",
        "                '⑶ - c: (Optional) Enter <b>Estimated incremental CPA</b>(Cost'\n",
        "                ' of intervention ÷ Lift from intervention without bias) & the '\n",
        "                'number of periodicities in the time series data.',\n",
        "            ),\n",
        "            ipywidgets.VBox([\n",
        "                self.estimate_icpa,\n",
        "                self.num_of_seasons,\n",
        "                self.credible_interval,\n",
        "            ]),\n",
        "        ]),\n",
        "    ]\n",
        "    self.purpose_selection.set_title(0, 'Causalimpact')\n",
        "    self.purpose_selection.set_title(1, 'Experimental_Design')\n",
        "\n",
        "    display(\n",
        "        PreProcess._apply_text_style(18, '⑴ Please select a data source.'),\n",
        "        self.soure_selection,\n",
        "        Markdown('<br>'),\n",
        "        PreProcess._apply_text_style(\n",
        "            18, '⑵ Please select wide or narrow data format.'\n",
        "        ),\n",
        "        self.data_type_selection,\n",
        "        Markdown('<br>'),\n",
        "        PreProcess._apply_text_style(\n",
        "            18, '⑶ Please select the purpose and set conditions.'\n",
        "        ),\n",
        "        self.purpose_selection,\n",
        "    )\n",
        "\n",
        "  def load_data(self):\n",
        "    if self.soure_selection.selected_index == 0:\n",
        "      try:\n",
        "        self.loaded_df = self._load_data_from_sheet(\n",
        "            self.sheet_url.value, self.sheet_name.value\n",
        "        )\n",
        "      except Exception as e:\n",
        "        self._apply_text_style('failure', '\\n\\nFailure!!')\n",
        "        print('Error: {}'.format(e))\n",
        "        print('Please check the following:')\n",
        "        print('* sheet url:{}'.format(self.sheet_url.value))\n",
        "        print('* sheet name:{}'.format(self.sheet_name.value))\n",
        "        raise Exception('Please check Failure')\n",
        "\n",
        "    elif self.soure_selection.selected_index == 1:\n",
        "      try:\n",
        "        self.loaded_df = self._load_data_from_csv(self.csv_name.value)\n",
        "      except Exception as e:\n",
        "        self._apply_text_style('failure', '\\n\\nFailure!!')\n",
        "        print('Error: {}'.format(e))\n",
        "        print('Please check the following:')\n",
        "        print('* There is something wrong with the CSV-related settings.')\n",
        "        print('* CSV namel:{}'.format(self.csv_name.value))\n",
        "        raise Exception('Please check Failure')\n",
        "\n",
        "    elif self.soure_selection.selected_index == 2:\n",
        "      try:\n",
        "        self.loaded_df = self._load_data_from_bigquery(\n",
        "            self.bq_project_id.value, self.bq_table_name.value\n",
        "        )\n",
        "      except Exception as e:\n",
        "        self._apply_text_style('failure', '\\n\\nFailure!!')\n",
        "        print('Error: {}'.format(e))\n",
        "        print('Please check the following:')\n",
        "        print('* There is something wrong with the bq-related settings.')\n",
        "        print('* bq project id:{}'.format(self.bq_project_id.value))\n",
        "        print('* bq table name :{}'.format(self.bq_table_name.value))\n",
        "        raise Exception('Please check Failure')\n",
        "\n",
        "    else:\n",
        "      raise Exception('Please select a data souce at Step.1-2.')\n",
        "\n",
        "    self._apply_text_style(\n",
        "        'success',\n",
        "        'Success! The target data has been loaded.')\n",
        "    display(self.loaded_df.head(3))\n",
        "\n",
        "  @staticmethod\n",
        "  def _load_data_from_sheet(spreadsheet_url, sheet_name):\n",
        "    \"\"\"load_data_from_sheet load data from spreadsheet.\n",
        "\n",
        "    Args:\n",
        "      spreadsheet_url: Spreadsheet url with data.\n",
        "      sheet_name: Sheet name with data.\n",
        "    \"\"\"\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "    _workbook = gc.open_by_url(spreadsheet_url)\n",
        "    _worksheet = _workbook.worksheet(sheet_name)\n",
        "    df_sheet = pd.DataFrame(_worksheet.get_all_values())\n",
        "    df_sheet.columns = list(df_sheet.loc[0, :])\n",
        "    df_sheet.drop(0, inplace=True)\n",
        "    df_sheet.reset_index(drop=True, inplace=True)\n",
        "    df_sheet.replace(',', '', regex=True, inplace=True)\n",
        "    df_sheet.rename(columns=lambda x: x.replace(\" \", \"\"), inplace=True)\n",
        "    df_sheet = df_sheet.apply(pd.to_numeric, errors='ignore')\n",
        "    return df_sheet\n",
        "\n",
        "  @staticmethod\n",
        "  def _load_data_from_csv(csv_name):\n",
        "    \"\"\"load_data_from_csv read data from csv.\n",
        "\n",
        "    Args:\n",
        "    csv_name: csv file name.\n",
        "    \"\"\"\n",
        "    uploaded = files.upload()\n",
        "    df_csv = pd.read_csv(io.BytesIO(uploaded[csv_name]))\n",
        "    df_csv.replace(',', '', regex=True, inplace=True)\n",
        "    df_csv.rename(columns=lambda x: x.replace(\" \", \"\"), inplace=True)\n",
        "    df_csv = df_csv.apply(pd.to_numeric, errors='ignore')\n",
        "    return df_csv\n",
        "\n",
        "  @staticmethod\n",
        "  def _load_data_from_bigquery(bq_project_id, bq_table_name):\n",
        "    \"\"\"_load_data_from_bigquery load data from bigquery.\n",
        "\n",
        "    Args:\n",
        "    bq_project_id: bigquery project id.\n",
        "    bq_table_name: bigquery table name\n",
        "    \"\"\"\n",
        "    auth.authenticate_user()\n",
        "    client = bigquery.Client(project=bq_project_id)\n",
        "    query = 'SELECT * FROM `' + bq_table_name + '`;'\n",
        "    df_bq = client.query(query).to_dataframe()\n",
        "    df_bq.replace(',', '', regex=True, inplace=True)\n",
        "    df_bq.rename(columns=lambda x: x.replace(\" \", \"\"), inplace=True)\n",
        "    df_bq = df_bq.apply(pd.to_numeric, errors='ignore')\n",
        "    return df_bq\n",
        "\n",
        "  def format_data(self):\n",
        "    \"\"\"Formats the loaded data for causal impact analysis or experimental design.\n",
        "\n",
        "    This method performs several data transformation steps:\n",
        "    1. Cleans column names by removing spaces from `date_col`, `pivot_col`, and `kpi_col`.\n",
        "    2. Converts the data to a wide format if specified by `data_type_selection`.\n",
        "    3. Drops columns specified in `exclude_cols`.\n",
        "    4. Converts the date column to datetime objects and sets it as the DataFrame index.\n",
        "    5. Reindexes the DataFrame to ensure a continuous date range from the minimum to maximum date.\n",
        "    6. Calculates `tick_count` for visualization purposes.\n",
        "    7. Provides visual feedback on the data formatting success or failure.\n",
        "    8. Displays an overview of the formatted data, including index, date range, and missing values.\n",
        "    9. Visualizes data trends (total and individual) and descriptive statistics.\n",
        "\n",
        "    Raises:\n",
        "        Exception: If any error occurs during data formatting, often due to\n",
        "                   mismatched data format selection (wide/narrow) or incorrect\n",
        "                   column names. Provides specific error messages to guide debugging.\n",
        "    \"\"\"\n",
        "    self.date_col_name = self.date_col.value.replace(' ', '')\n",
        "    self.pivot_col_name = self.pivot_col.value.replace(' ', '')\n",
        "    self.kpi_col_name = self.kpi_col.value.replace(' ', '')\n",
        "\n",
        "    try:\n",
        "      if self.data_type_selection.selected_index == 0:\n",
        "        self.formatted_data = self.loaded_df.copy()\n",
        "      elif self.data_type_selection.selected_index == 1:\n",
        "        self.formatted_data = self._shape_wide(\n",
        "            self.loaded_df,\n",
        "            self.date_col_name,\n",
        "            self.pivot_col_name,\n",
        "            self.kpi_col_name,\n",
        "        )\n",
        "\n",
        "      self.formatted_data.drop(\n",
        "          self.exclude_cols.value.replace(', ', ',').split(','),\n",
        "          axis=1,\n",
        "          errors='ignore',\n",
        "          inplace=True,\n",
        "      )\n",
        "      self.formatted_data[self.date_col_name] = pd.to_datetime(\n",
        "          self.formatted_data[self.date_col_name]\n",
        "      )\n",
        "      self.formatted_data = self.formatted_data.set_index(self.date_col_name)\n",
        "      self.formatted_data = self.formatted_data.reindex(\n",
        "          pd.date_range(\n",
        "              start=self.formatted_data.index.min(),\n",
        "              end=self.formatted_data.index.max(),\n",
        "              name=self.formatted_data.index.name))\n",
        "      self.tick_count = len(self.formatted_data.resample('M')) - 1\n",
        "      self._apply_text_style(\n",
        "          'success',\n",
        "          '\\nSuccess! The data was formatted for analysis.'\n",
        "          )\n",
        "      display(self.formatted_data.head(3))\n",
        "      self._apply_text_style(\n",
        "          'failure',\n",
        "          '\\nCheck! Here is an overview of the data.'\n",
        "          )\n",
        "      print(\n",
        "          'Index name:{} | The earliest date: {} | The latest date: {}'.format(\n",
        "              self.formatted_data.index.name,\n",
        "              min(self.formatted_data.index),\n",
        "              max(self.formatted_data.index)\n",
        "              ))\n",
        "      print('* Rows with missing values')\n",
        "      self.missing_row = self.formatted_data[\n",
        "          self.formatted_data.isnull().any(axis=1)]\n",
        "      if len(self.missing_row) > 0:\n",
        "        self.missing_row\n",
        "      else:\n",
        "        print('>> Does not include missing values')\n",
        "\n",
        "      self._apply_text_style(\n",
        "          'failure',\n",
        "          '\\nCheck! below [total_trend] / [each_trend] / [describe_data]'\n",
        "          )\n",
        "      self._trend_check(\n",
        "          self.formatted_data,\n",
        "          self.date_col_name,\n",
        "          self.tick_count)\n",
        "\n",
        "    except Exception as e:\n",
        "      self._apply_text_style('failure', '\\n\\nFailure!!')\n",
        "      print('Error: {}'.format(e))\n",
        "      self._apply_text_style('failure', '\\nPlease check the following:')\n",
        "      if self.data_type_selection.selected_index == 0:\n",
        "        print('* Your selected data format: Wide format at (2)')\n",
        "        print('1. Check if the data source is wide.')\n",
        "        print('2. Compare \"date column\"( {} ) and \"data source\"'.format(\n",
        "            self.date_col.value))\n",
        "        print('\\n\\n')\n",
        "      else:\n",
        "        print('* Your selected data format: Narrow format at (2)')\n",
        "        print('1. Check if the data source is narrow.')\n",
        "        print('2. Compare \"your input\" and \"data source')\n",
        "        print('>> date column: {}'.format(self.date_col.value))\n",
        "        print('>> pivot column: {}'.format(self.pivot_col.value))\n",
        "        print('>> kpi column: {}'.format(self.kpi_col.value))\n",
        "        print('\\n\\n')\n",
        "      raise Exception('Please check Failure')\n",
        "\n",
        "  @staticmethod\n",
        "  def _shape_wide(dataframe, date_column, pivot_column, kpi_column):\n",
        "    \"\"\"shape_wide pivots the data in the specified column.\n",
        "\n",
        "    Converts long data to wide data suitable for experiment design.\n",
        "\n",
        "    Args:\n",
        "        dataframe: The DataFrame to be pivoted.\n",
        "        date_column: The name of the column that contains the dates.\n",
        "        pivot_column: The name of the column that contains the pivot keys.\n",
        "        kpi_column: The name of the column that contains the KPI values.\n",
        "\n",
        "    Returns:\n",
        "        A DataFrame with the pivoted data.\n",
        "    \"\"\"\n",
        "    # Check if the pivot_column is a single column or a list of columns.\n",
        "    if ',' in pivot_column:\n",
        "      group_cols = pivot_column.replace(', ', ',').split(',')\n",
        "    else:\n",
        "      group_cols = [pivot_column]\n",
        "\n",
        "    pivoted_df = pd.pivot_table(\n",
        "        (dataframe[[date_column] + [kpi_column] + group_cols])\n",
        "        .groupby([date_column] + group_cols)\n",
        "        .sum(),\n",
        "        index=date_column,\n",
        "        columns=group_cols,\n",
        "        fill_value=0,\n",
        "    )\n",
        "    # Drop the first level of the column names.\n",
        "    pivoted_df.columns = pivoted_df.columns.droplevel(0)\n",
        "    # If there are multiple columns, convert the column names to a single string.\n",
        "    if len(pivoted_df.columns.names) > 1:\n",
        "      new_cols = [\n",
        "          '_'.join([x.replace(',', '_') for x in y])\n",
        "          for y in pivoted_df.columns.values\n",
        "      ]\n",
        "      pivoted_df.columns = new_cols\n",
        "    pivoted_df = pivoted_df.reset_index()\n",
        "    return pivoted_df\n",
        "\n",
        "  @staticmethod\n",
        "  def _trend_check(dataframe, date_col_name, tick_count):\n",
        "    \"\"\"trend_check visualize daily trend, 7-day moving average\n",
        "\n",
        "    Args:\n",
        "      dataframe: Wide data to check the trend\n",
        "      date_col_name: xxx\n",
        "    \"\"\"\n",
        "    df_each = pd.DataFrame(index=dataframe.index)\n",
        "    col_list = list(dataframe.columns)\n",
        "    for i in col_list:\n",
        "      min_max = (\n",
        "          dataframe[i] - dataframe[i].min()\n",
        "          ) / (dataframe[i].max() - dataframe[i].min())\n",
        "      df_each = pd.concat([df_each, min_max], axis = 1)\n",
        "\n",
        "    metric = 'dtw'\n",
        "    n_clusters = 5\n",
        "    tskm_base = TimeSeriesKMeans(n_clusters=n_clusters, metric=metric,\n",
        "                             max_iter=100, random_state=42)\n",
        "    df_cluster = pd.DataFrame({\n",
        "        \"pivot\": col_list,\n",
        "        \"cluster\": tskm_base.fit_predict(df_each.T).tolist()})\n",
        "    cluster_counts = (\n",
        "        df_cluster[\"cluster\"].value_counts().sort_values(ascending=True))\n",
        "\n",
        "    cluster_text = []\n",
        "    line_each = []\n",
        "    for i in cluster_counts.index:\n",
        "      clust_list = df_cluster.query(\"cluster == @i\")[\"pivot\"].to_list()\n",
        "      source = df_each.filter(items=clust_list)\n",
        "      cluster_text.append(str(clust_list).translate(\n",
        "          str.maketrans({'[': '', ']': '',  \"'\": ''})))\n",
        "      line_each.append(\n",
        "          alt.Chart(source.reset_index())\n",
        "          .transform_fold(fold=clust_list, as_=['pivot', 'kpi'])\n",
        "          .mark_line()\n",
        "          .encode(\n",
        "              alt.X(\n",
        "                  date_col_name + ':T',\n",
        "                  title=None,\n",
        "                  axis=alt.Axis(\n",
        "                      grid=False, format='%Y %b', tickCount=tick_count\n",
        "                      ),\n",
        "                  ),\n",
        "              alt.Y('kpi:Q', stack=None, axis=None),\n",
        "              alt.Color(str(i) + ':N', title=None, legend=None),\n",
        "              alt.Row(\n",
        "                  'pivot:N',\n",
        "                  title=None,\n",
        "                  header=alt.Header(labelAngle=0, labelAlign='left'),\n",
        "                  ),\n",
        "              )\n",
        "          .properties(bounds='flush', height=30)\n",
        "          .configure_facet(spacing=0)\n",
        "          .configure_view(stroke=None)\n",
        "          .configure_title(anchor='end')\n",
        "          )\n",
        "\n",
        "    df_long = (\n",
        "        pd.melt(dataframe.reset_index(), id_vars=date_col_name)\n",
        "        .groupby(date_col_name)\n",
        "        .sum(numeric_only=True)\n",
        "        .reset_index()\n",
        "    )\n",
        "    line_total = (\n",
        "        alt.Chart(df_long)\n",
        "        .mark_line()\n",
        "        .encode(\n",
        "            x=alt.X(\n",
        "                date_col_name + ':T',\n",
        "                axis=alt.Axis(\n",
        "                    title='', format='%Y %b', tickCount=tick_count\n",
        "                ),\n",
        "            ),\n",
        "            y=alt.Y('value:Q', axis=alt.Axis(title='kpi')),\n",
        "            color=alt.value('#4285F4'),\n",
        "        )\n",
        "    )\n",
        "    moving_average = (\n",
        "        alt.Chart(df_long)\n",
        "        .transform_window(\n",
        "            rolling_mean='mean(value)',\n",
        "            frame=[-4, 3],\n",
        "        )\n",
        "        .mark_line()\n",
        "        .encode(\n",
        "            x=alt.X(date_col_name + ':T'),\n",
        "            y=alt.Y('rolling_mean:Q'),\n",
        "            color=alt.value('#DB4437'),\n",
        "        )\n",
        "    )\n",
        "    tab_total_trend = ipywidgets.Output()\n",
        "    tab_each_trend = ipywidgets.Output()\n",
        "    tab_describe_data = ipywidgets.Output()\n",
        "    tab_result = ipywidgets.Tab(children = [\n",
        "        tab_total_trend,\n",
        "        tab_each_trend,\n",
        "        tab_describe_data,\n",
        "        ])\n",
        "    tab_result.set_title(0, '>> total_trend')\n",
        "    tab_result.set_title(1, '>> each_trend')\n",
        "    tab_result.set_title(2, '>> describe_data')\n",
        "    display(tab_result)\n",
        "    with tab_total_trend:\n",
        "      display(\n",
        "          (line_total + moving_average).properties(\n",
        "              width=700,\n",
        "              height=200,\n",
        "              title={\n",
        "                  'text': ['Daily Trend(blue) & 7days moving average(red)'],\n",
        "              },\n",
        "          )\n",
        "      )\n",
        "    with tab_each_trend:\n",
        "      for i in range(len(cluster_text)):\n",
        "          print('cluster {}:{}'.format(i, cluster_text[i]))\n",
        "          display(line_each[i].properties(width=700))\n",
        "    with tab_describe_data:\n",
        "      display(dataframe.describe(include='all'))\n",
        "\n",
        "  @staticmethod\n",
        "  def saving_params(instance):\n",
        "    params_dict = {\n",
        "        # section for data source\n",
        "        'soure_selection': instance.soure_selection.selected_index,\n",
        "        'sheet_url': instance.sheet_url.value,\n",
        "        'sheet_name': instance.sheet_name.value,\n",
        "        'csv_name': instance.csv_name.value,\n",
        "        'bq_project_id': instance.bq_project_id.value,\n",
        "        'bq_table_name': instance.bq_table_name.value,\n",
        "\n",
        "        # section for data format(narrow or wide)\n",
        "        'data_type_selection': instance.data_type_selection.selected_index,\n",
        "        'date_col': instance.date_col.value,\n",
        "        'pivot_col': instance.pivot_col.value,\n",
        "        'kpi_col': instance.kpi_col.value,\n",
        "\n",
        "        # section for porpose(CausalImpact or Experimental Design)\n",
        "        'purpose_selection': instance.purpose_selection.selected_index,\n",
        "        'pre_period_start': instance.pre_period_start.value,\n",
        "        'pre_period_end': instance.pre_period_end.value,\n",
        "        'post_period_start': instance.post_period_start.value,\n",
        "        'post_period_end': instance.post_period_end.value,\n",
        "        'start_date': instance.start_date.value,\n",
        "        'end_date': instance.end_date.value,\n",
        "        'depend_data': instance.depend_data.value,\n",
        "\n",
        "        'design_type': instance.design_type.selected_index,\n",
        "        'num_of_split': instance.num_of_split.value,\n",
        "        'target_columns': instance.target_columns.value,\n",
        "        'control_columns': instance.control_columns.value,\n",
        "        'num_of_pick_range': instance.num_of_pick_range.value,\n",
        "        'num_of_covariate': instance.num_of_covariate.value,\n",
        "        'target_share': instance.target_share.value,\n",
        "        'exclude_cols': instance.exclude_cols.value,\n",
        "\n",
        "        'num_of_seasons': instance.num_of_seasons.value,\n",
        "        'estimate_icpa': instance.estimate_icpa.value,\n",
        "        'credible_interval': instance.credible_interval.value,\n",
        "        }\n",
        "    return params_dict\n",
        "\n",
        "  @staticmethod\n",
        "  def set_params(instance, dict_params):\n",
        "    # section for data source\n",
        "    instance.soure_selection.selected_index = dict_params['soure_selection']\n",
        "    instance.sheet_url.value = dict_params['sheet_url']\n",
        "    instance.sheet_name.value = dict_params['sheet_name']\n",
        "    instance.csv_name.value = dict_params['csv_name']\n",
        "    instance.bq_project_id.value = dict_params['bq_project_id']\n",
        "    instance.bq_table_name.value = dict_params['bq_table_name']\n",
        "\n",
        "    # section for data format(narrow or wide)\n",
        "    instance.data_type_selection.selected_index = dict_params['data_type_selection']\n",
        "    instance.date_col.value = dict_params['date_col']\n",
        "    instance.pivot_col.value = dict_params['pivot_col']\n",
        "    instance.kpi_col.value = dict_params['kpi_col']\n",
        "\n",
        "    # section for porpose(CausalImpact or Experimental Design)\n",
        "    instance.purpose_selection.selected_index = dict_params['purpose_selection']\n",
        "    instance.pre_period_start.value = dict_params['pre_period_start']\n",
        "    instance.pre_period_end.value = dict_params['pre_period_end']\n",
        "    instance.post_period_start.value = dict_params['post_period_start']\n",
        "    instance.post_period_end.value = dict_params['post_period_end']\n",
        "    instance.start_date.value = dict_params['start_date']\n",
        "    instance.end_date.value = dict_params['end_date']\n",
        "    instance.depend_data.value = dict_params['depend_data']\n",
        "\n",
        "    instance.design_type.selected_index = dict_params['design_type']\n",
        "    instance.num_of_split.value = dict_params['num_of_split']\n",
        "    instance.target_columns.value = dict_params['target_columns']\n",
        "    instance.control_columns.value = dict_params['control_columns']\n",
        "    instance.num_of_pick_range.value = dict_params['num_of_pick_range']\n",
        "    instance.num_of_covariate.value = dict_params['num_of_covariate']\n",
        "    instance.target_share.value = dict_params['target_share']\n",
        "    instance.exclude_cols.value = dict_params['exclude_cols']\n",
        "\n",
        "    instance.num_of_seasons.value = dict_params['num_of_seasons']\n",
        "    instance.estimate_icpa.value = dict_params['estimate_icpa']\n",
        "    instance.credible_interval.value = dict_params['credible_interval']\n",
        "\n",
        "# @title dev\n",
        "class CausalImpact(PreProcess):\n",
        "  \"\"\"CausalImpact analysis and experimental design on CausalImpact.\n",
        "\n",
        "  CausalImpact Analysis performs a CausalImpact analysis on the given data and\n",
        "  outputs the results. The experimental design will be based on N partitions,\n",
        "  similarity, or share, with 1000 iterations of random sampling, and will output\n",
        "  the three candidate groups with the closest DTW distance. A combination of\n",
        "  increments and periods will be used to simulate and return which combination\n",
        "  will result in a significantly different validation.\n",
        "\n",
        "  Attributes:\n",
        "    run_causalImpact: Runs CausalImpact on the given case.\n",
        "    create_causalimpact_object:\n",
        "    display_causalimpact_result:\n",
        "    plot_causalimpact:\n",
        "\n",
        "  Returns:\n",
        "    The CausalImpact object.\n",
        "  \"\"\"\n",
        "\n",
        "  colors = [\n",
        "      '#DB4437',\n",
        "      '#AB47BC',\n",
        "      '#4285F4',\n",
        "      '#00ACC1',\n",
        "      '#0F9D58',\n",
        "      '#9E9D24',\n",
        "      '#F4B400',\n",
        "      '#FF7043',\n",
        "  ]\n",
        "  NUM_OF_ITERATION = 1000\n",
        "  COMBINATION_TARGET = 10\n",
        "  TREAT_DURATION = [14, 21, 28]\n",
        "  TREAT_IMPACT = [1, 1.01, 1.03, 1.05, 1.10, 1.15]\n",
        "  MAX_STRING_LENGTH = 150\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def run_causalImpact(self):\n",
        "    self.ci_objs = []\n",
        "    try:\n",
        "      self.ci_obj = self.create_causalimpact_object(\n",
        "          self.formatted_data,\n",
        "          self.date_col_name,\n",
        "          self.pre_period_start.value,\n",
        "          self.pre_period_end.value,\n",
        "          self.post_period_start.value,\n",
        "          self.post_period_end.value,\n",
        "          self.num_of_seasons.value,\n",
        "          self.credible_interval.value,\n",
        "      )\n",
        "      self.ci_objs.append(self.ci_obj)\n",
        "      self._apply_text_style(\n",
        "          'success',\n",
        "          '\\nSuccess! CausalImpact has been performed. Check the'\n",
        "          ' results in the next cell.',\n",
        "      )\n",
        "\n",
        "    except Exception as e:\n",
        "      self._apply_text_style('failure', '\\n\\nFailure!!')\n",
        "      print('Error: {}'.format(e))\n",
        "      print('Please check the following:')\n",
        "      print('* Date source.')\n",
        "      print('* Date Column Name.')\n",
        "      print('* Duration of experiment (pre and post).')\n",
        "      raise Exception('Please check Failure')\n",
        "\n",
        "  @staticmethod\n",
        "  def create_causalimpact_object(\n",
        "      data,\n",
        "      date_col,\n",
        "      pre_start,\n",
        "      pre_end,\n",
        "      post_start,\n",
        "      post_end,\n",
        "      num_of_seasons,\n",
        "      credible_interval):\n",
        "    if data.index.name != date_col: data.set_index(date_col, inplace=True)\n",
        "\n",
        "    if num_of_seasons == 1:\n",
        "      causalimpact_object = causalimpact.fit_causalimpact(\n",
        "          data=data,\n",
        "          pre_period=(str(pre_start), str(pre_end)),\n",
        "          post_period=(str(post_start), str(post_end)),\n",
        "          alpha= 1 - credible_interval / 100,\n",
        "      )\n",
        "    else:\n",
        "      causalimpact_object = causalimpact.fit_causalimpact(\n",
        "          data=data,\n",
        "          pre_period=(str(pre_start), str(pre_end)),\n",
        "          post_period=(str(post_start), str(post_end)),\n",
        "          alpha= 1 - credible_interval / 100,\n",
        "          model_options=causalimpact.ModelOptions(\n",
        "              seasons=[\n",
        "                  causalimpact.Seasons(num_seasons=num_of_seasons),\n",
        "              ]\n",
        "          ),\n",
        "      )\n",
        "    return causalimpact_object\n",
        "\n",
        "  def display_causalimpact_result(self):\n",
        "    print('Test & Control Time Series')\n",
        "    line = (\n",
        "        alt.Chart(self.formatted_data.reset_index())\n",
        "        .transform_fold(list(self.formatted_data.columns))\n",
        "        .mark_line()\n",
        "        .encode(\n",
        "            alt.X(\n",
        "                self.date_col_name + ':T',\n",
        "                title=None,\n",
        "                axis=alt.Axis(format='%Y %b', tickCount=self.tick_count),\n",
        "            ),\n",
        "            y=alt.Y('value:Q', axis=alt.Axis(title='kpi')),\n",
        "            color=alt.Color(\n",
        "                'key:N',\n",
        "                legend=alt.Legend(\n",
        "                    title=None,\n",
        "                    orient='none',\n",
        "                    legendY=-20,\n",
        "                    direction='horizontal',\n",
        "                    titleAnchor='start',\n",
        "                ),\n",
        "                scale=alt.Scale(\n",
        "                    domain=list(self.formatted_data.columns),\n",
        "                    range=CausalImpact.colors,\n",
        "                ),\n",
        "            ),\n",
        "        )\n",
        "        .properties(height=200, width=600)\n",
        "    )\n",
        "    rule = (\n",
        "        alt.Chart(\n",
        "          pd.DataFrame({\n",
        "            'Date': [\n",
        "                str(self.post_period_start.value),\n",
        "                str(self.post_period_end.value)\n",
        "                ],\n",
        "            'color': ['red', 'orange'],\n",
        "            })\n",
        "          )\n",
        "        .mark_rule(strokeDash=[5, 5])\n",
        "        .encode(x='Date:T', color=alt.Color('color:N', scale=None))\n",
        "        )\n",
        "    display((line+rule).properties(height=200, width=600))\n",
        "    print('=' * 100)\n",
        "\n",
        "    self.plot_causalimpact(\n",
        "        self.ci_objs[0],\n",
        "        self.pre_period_start.value,\n",
        "        self.pre_period_end.value,\n",
        "        self.post_period_start.value,\n",
        "        self.post_period_end.value,\n",
        "        self.credible_interval.value,\n",
        "        self.date_col_name,\n",
        "        self.tick_count,\n",
        "        self.purpose_selection.selected_index\n",
        "    )\n",
        "\n",
        "  @staticmethod\n",
        "  def plot_causalimpact(\n",
        "      causalimpact_object,\n",
        "      pre_start,\n",
        "      pre_end,\n",
        "      tread_start,\n",
        "      treat_end,\n",
        "      credible_interval,\n",
        "      date_col_name,\n",
        "      tick_count,\n",
        "      purpose_selection\n",
        "    ):\n",
        "    causalimpact_df = causalimpact_object.series#.copy()\n",
        "    mape = mean_absolute_percentage_error(\n",
        "        causalimpact_df['observed'][str(pre_start) : str(pre_end)],\n",
        "        causalimpact_df['posterior_mean'][str(pre_start) : str(pre_end)],\n",
        "    )\n",
        "    threshold = round(1 - credible_interval / 100, 2)\n",
        "\n",
        "    line_1 = (\n",
        "        alt.Chart(causalimpact_df.reset_index())\n",
        "        .transform_fold([\n",
        "            'observed',\n",
        "            'posterior_mean',\n",
        "        ])\n",
        "        .mark_line()\n",
        "        .encode(\n",
        "            x=alt.X(\n",
        "                'yearmonthdate(' + date_col_name + ')',\n",
        "                axis=alt.Axis(\n",
        "                    title='',\n",
        "                    labels=False,\n",
        "                    ticks=False,\n",
        "                    format='%Y %b',\n",
        "                    tickCount=tick_count,\n",
        "                ),\n",
        "            ),\n",
        "            y=alt.Y(\n",
        "                'value:Q',\n",
        "                scale=alt.Scale(zero=False),\n",
        "                axis=alt.Axis(title=''),\n",
        "            ),\n",
        "            color=alt.Color(\n",
        "                'key:N',\n",
        "                legend=alt.Legend(\n",
        "                    title=None,\n",
        "                    orient='none',\n",
        "                    legendY=-20,\n",
        "                    direction='horizontal',\n",
        "                    titleAnchor='start',\n",
        "                ),\n",
        "                sort=['posterior_mean', 'observed'],\n",
        "            ),\n",
        "            strokeDash=alt.condition(\n",
        "                alt.datum.key == 'posterior_mean',\n",
        "                alt.value([5, 5]),\n",
        "                alt.value([0]),\n",
        "            ),\n",
        "        )\n",
        "    )\n",
        "    area_1 = (\n",
        "        alt.Chart(causalimpact_df.reset_index())\n",
        "        .mark_area(opacity=0.3)\n",
        "        .encode(\n",
        "            x=alt.X('yearmonthdate(' + date_col_name + ')'),\n",
        "            y=alt.Y('posterior_lower:Q', scale=alt.Scale(zero=False)),\n",
        "            y2=alt.Y2('posterior_upper:Q'),\n",
        "        )\n",
        "    )\n",
        "    line_2 = (\n",
        "        alt.Chart(causalimpact_df.reset_index())\n",
        "        .mark_line(strokeDash=[5, 5])\n",
        "        .encode(\n",
        "            x=alt.X(\n",
        "                'yearmonthdate(' + date_col_name + ')',\n",
        "                axis=alt.Axis(\n",
        "                    title='',\n",
        "                    labels=False,\n",
        "                    ticks=False,\n",
        "                    format='%Y %b',\n",
        "                    tickCount=tick_count,\n",
        "                ),\n",
        "            ),\n",
        "            y=alt.Y(\n",
        "                'point_effects_mean:Q',\n",
        "                scale=alt.Scale(zero=False),\n",
        "                axis=alt.Axis(title=''),\n",
        "            ),\n",
        "        )\n",
        "    )\n",
        "    area_2 = (\n",
        "        alt.Chart(causalimpact_df.reset_index())\n",
        "        .mark_area(opacity=0.3)\n",
        "        .encode(\n",
        "            x=alt.X('yearmonthdate(' + date_col_name + ')'),\n",
        "            y=alt.Y('point_effects_lower:Q', scale=alt.Scale(zero=False)),\n",
        "            y2=alt.Y2('point_effects_upper:Q'),\n",
        "        )\n",
        "    )\n",
        "    line_3 = (\n",
        "        alt.Chart(causalimpact_df.reset_index())\n",
        "        .mark_line(strokeDash=[5, 5])\n",
        "        .encode(\n",
        "            x=alt.X(\n",
        "                'yearmonthdate(' + date_col_name + ')',\n",
        "                axis=alt.Axis(title='', format='%Y %b', tickCount=tick_count),\n",
        "            ),\n",
        "            y=alt.Y(\n",
        "                'cumulative_effects_mean:Q',\n",
        "                scale=alt.Scale(zero=False),\n",
        "                axis=alt.Axis(title=''),\n",
        "            ),\n",
        "        )\n",
        "    )\n",
        "    area_3 = (\n",
        "        alt.Chart(causalimpact_df.reset_index())\n",
        "        .mark_area(opacity=0.3)\n",
        "        .encode(\n",
        "            x=alt.X(\n",
        "                'yearmonthdate(' + date_col_name + ')',\n",
        "                axis=alt.Axis(title='')),\n",
        "            y=alt.Y('cumulative_effects_lower:Q', scale=alt.Scale(zero=False),\n",
        "                    axis=alt.Axis(title='')),\n",
        "            y2=alt.Y2('cumulative_effects_upper:Q'),\n",
        "        )\n",
        "    )\n",
        "    zero_line = (\n",
        "        alt.Chart(pd.DataFrame({'y': [0]}))\n",
        "        .mark_rule()\n",
        "        .encode(y='y', color=alt.value('gray'))\n",
        "    )\n",
        "    rules = (\n",
        "        alt.Chart(\n",
        "            pd.DataFrame({\n",
        "                'Date': [str(tread_start), str(treat_end)],\n",
        "                'color': ['red', 'orange'],\n",
        "            })\n",
        "        )\n",
        "        .mark_rule(strokeDash=[5, 5])\n",
        "        .encode(x='Date:T', color=alt.Color('color:N', scale=None))\n",
        "    )\n",
        "    watermark = alt.Chart(pd.DataFrame([1])).mark_text(\n",
        "        align='center',\n",
        "        dx=0,\n",
        "        dy=0,\n",
        "        fontSize=48,\n",
        "        text='mock experiment',\n",
        "        color='red'\n",
        "      ).encode(\n",
        "        opacity=alt.value(0.5)\n",
        "    )\n",
        "    if purpose_selection == 1:\n",
        "      cumulative = line_3 + area_3 + rules + zero_line + watermark\n",
        "    elif causalimpact_object.summary.p_value.average >= threshold:\n",
        "      cumulative = area_3 + rules + zero_line\n",
        "    else:\n",
        "      cumulative = line_3 + area_3 + rules + zero_line\n",
        "    plot = alt.vconcat(\n",
        "        (line_1 + area_1 + rules).properties(height=100, width=600),\n",
        "        (line_2 + area_2 + rules + zero_line).properties(height=100, width=600),\n",
        "        (cumulative).properties(height=100, width=600),\n",
        "    )\n",
        "\n",
        "    tab_data = ipywidgets.Output()\n",
        "    tab_report = ipywidgets.Output()\n",
        "    tab_summary = ipywidgets.Output()\n",
        "    tab_result = ipywidgets.Tab(children = [tab_summary, tab_report, tab_data])\n",
        "    tab_result.set_title(0, '>> summary')\n",
        "    tab_result.set_title(1, '>> report')\n",
        "    tab_result.set_title(2, '>> data')\n",
        "    with tab_summary:\n",
        "      print('Approximate model accuracy >> MAPE:{:.2%}'.format(mape))\n",
        "      if mape <= 0.05:\n",
        "          PreProcess._apply_text_style(\n",
        "              'success',\n",
        "              'Very Good: The difference between actual and predicted values ​​is slight.')\n",
        "      elif mape <= 0.10:\n",
        "          PreProcess._apply_text_style(\n",
        "              'success',\n",
        "              'Good: The difference between the actual and predicted values ​​is within the acceptable range.')\n",
        "      elif mape <= 0.15:\n",
        "          PreProcess._apply_text_style(\n",
        "              'failure',\n",
        "              'Medium: he difference between the actual and predicted values ​​ismoderate, so this is only a reference value.')\n",
        "      else:\n",
        "          PreProcess._apply_text_style(\n",
        "              'failure',\n",
        "              'Bad: The difference between actual and predicted values ​​is large, so we do not recommend using it.')\n",
        "      if causalimpact_object.summary.p_value.average <= threshold:\n",
        "          PreProcess._apply_text_style('success', f'\\nP-Value is under {threshold}. There is a statistically significant difference.')\n",
        "      else:\n",
        "          PreProcess._apply_text_style('failure', f'\\nP-Value is over {threshold}. There is not a statistically significant difference.')\n",
        "\n",
        "      print(causalimpact.summary(\n",
        "          causalimpact_object,\n",
        "          output_format='summary',\n",
        "          alpha= 1 - credible_interval / 100))\n",
        "      display(plot)\n",
        "    with tab_report:\n",
        "      print(causalimpact.summary(\n",
        "          causalimpact_object,\n",
        "          output_format=\"report\",\n",
        "          alpha= 1 - credible_interval / 100))\n",
        "    with tab_data:\n",
        "      df = causalimpact_object.series\n",
        "      df.insert(2, 'diff_percentage', df['point_effects_mean'] / df['observed'])\n",
        "      display(df)\n",
        "    display(tab_result)\n",
        "\n",
        "  def run_experimental_design(self):\n",
        "    if self.date_selection.selected_index == 0:\n",
        "      self.start_date_value = min(self.formatted_data.index).date()\n",
        "      self.end_date_value = max(self.formatted_data.index).date()\n",
        "    else:\n",
        "      self.start_date_value = self.start_date.value\n",
        "      self.end_date_value = self.end_date.value\n",
        "\n",
        "    if self.design_type.selected_index == 0:\n",
        "      self.distance_data = self._n_part_split(\n",
        "          self.formatted_data.query(\n",
        "              '@self.start_date_value <= index <= @self.end_date_value'\n",
        "              ),\n",
        "          self.num_of_split.value,\n",
        "          CausalImpact.NUM_OF_ITERATION\n",
        "      )\n",
        "    elif self.design_type.selected_index == 1:\n",
        "      self.distance_data = self._find_similar(\n",
        "          self.formatted_data.query(\n",
        "              '@self.start_date_value <= index <= @self.end_date_value'\n",
        "              ),\n",
        "          self.target_columns.value,\n",
        "          self.num_of_pick_range.value,\n",
        "          self.num_of_covariate.value\n",
        "      )\n",
        "    elif self.design_type.selected_index == 2:\n",
        "      self.distance_data = self._from_share(\n",
        "          self.formatted_data.query(\n",
        "              '@self.start_date_value <= index <= @self.end_date_value'\n",
        "              ),\n",
        "          self.target_share.value,\n",
        "      )\n",
        "    elif self.design_type.selected_index == 3:\n",
        "      self.distance_data = self._given_assignment(\n",
        "          self.target_columns.value,\n",
        "          self.control_columns.value,\n",
        "      )\n",
        "    else:\n",
        "      self._apply_text_style('failure', '\\n\\nFailure!!')\n",
        "      print('Please check the following:')\n",
        "      print('* There is something wrong with design type.')\n",
        "      raise Exception('Please check Failure')\n",
        "\n",
        "    self._visualize_candidate(\n",
        "        self.formatted_data,\n",
        "        self.distance_data,\n",
        "        self.start_date_value,\n",
        "        self.end_date_value,\n",
        "        self.date_col_name,\n",
        "        self.tick_count\n",
        "    )\n",
        "    self._generate_choice()\n",
        "\n",
        "  @staticmethod\n",
        "  def _n_part_split(dataframe, num_of_split, NUM_OF_ITERATION):\n",
        "    \"\"\"n_part_split\n",
        "\n",
        "    Args:\n",
        "      dataframe: xxx.\n",
        "      num_of_split: xxx.\n",
        "      NUM_OF_ITERATION: xxx.\n",
        "    \"\"\"\n",
        "    distance_data = pd.DataFrame(columns=['distance'])\n",
        "    num_of_pick = len(dataframe.columns) // num_of_split\n",
        "\n",
        "    for l in tqdm(range(NUM_OF_ITERATION)):\n",
        "      col_list = list(dataframe.columns)\n",
        "      picked_data = pd.DataFrame()\n",
        "\n",
        "      # random pick\n",
        "      picks = []\n",
        "      for s in range(num_of_split):\n",
        "        random_pick = random.sample(col_list, num_of_pick)\n",
        "        picks.append(random_pick)\n",
        "        col_list = [i for i in col_list if i not in random_pick]\n",
        "      picks[0].extend(col_list)\n",
        "\n",
        "      for i in range(len(picks)):\n",
        "        picked_data = pd.concat([\n",
        "            picked_data,\n",
        "            pd.DataFrame(dataframe[picks[i]].sum(axis=1), columns=[i])\n",
        "            ], axis=1)\n",
        "\n",
        "      # calculate distance\n",
        "      distance = CausalImpact._calculate_distance(\n",
        "          picked_data.reset_index(drop=True)\n",
        "      )\n",
        "      distance_data.loc[l, 'distance'] = float(distance)\n",
        "      for j in range(len(picks)):\n",
        "        distance_data.at[l, j] = str(sorted(picks[j]))\n",
        "\n",
        "    distance_data = (\n",
        "        distance_data.drop_duplicates()\n",
        "        .sort_values('distance')\n",
        "        .head(3)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    return distance_data\n",
        "\n",
        "  @staticmethod\n",
        "  def _find_similar(\n",
        "      dataframe,\n",
        "      target_columns,\n",
        "      num_of_pick_range,\n",
        "      num_of_covariate,\n",
        "      ):\n",
        "    distance_data = pd.DataFrame(columns=['distance'])\n",
        "    target_cols = target_columns.replace(', ', ',').split(',')\n",
        "\n",
        "    # An error occurs when the number of candidates (max num_of_range times\n",
        "    # num_of_covariates) is greater than num_of_columns excluding target column.\n",
        "    if (\n",
        "        len(dataframe.columns) - len(target_cols)\n",
        "          >= num_of_pick_range[1] * num_of_covariate):\n",
        "      pass\n",
        "    else:\n",
        "      print('Please check the following:')\n",
        "      print('* There is something wrong with similarity settings.')\n",
        "      print('* Total number of columns ー the target = {}'.format(\n",
        "          len(dataframe.columns) - len(target_cols)))\n",
        "      print('* But your settings are {}(max pick#) × {}(covariate#)'.format(\n",
        "          num_of_pick_range[1], num_of_covariate))\n",
        "      print('* Please set it so that it does not exceed.')\n",
        "      PreProcess._apply_text_style('failure', '▲▲▲▲▲▲\\n\\n')\n",
        "      raise Exception('Please check Failure')\n",
        "\n",
        "    for l in tqdm(range(CausalImpact.NUM_OF_ITERATION)):\n",
        "      picked_data = pd.DataFrame()\n",
        "      remained_list = [\n",
        "          i for i in list(dataframe.columns) if i not in target_cols\n",
        "      ]\n",
        "      picks = []\n",
        "      for s in range(num_of_covariate):\n",
        "        pick = random.sample(remained_list, random.randrange(\n",
        "            num_of_pick_range[0], num_of_pick_range[1] + 1, 1\n",
        "            )\n",
        "        )\n",
        "        picks.append(pick)\n",
        "        remained_list = [\n",
        "            ele for ele in remained_list if ele not in pick\n",
        "        ]\n",
        "      picks.insert(0, target_cols)\n",
        "      for i in range(len(picks)):\n",
        "        picked_data = pd.concat([\n",
        "            picked_data,\n",
        "            pd.DataFrame(dataframe[picks[i]].sum(axis=1), columns=[i])\n",
        "            ], axis=1)\n",
        "\n",
        "      # calculate distance\n",
        "      distance = CausalImpact._calculate_distance(\n",
        "          picked_data.reset_index(drop=True)\n",
        "      )\n",
        "      distance_data.loc[l, 'distance'] = float(distance)\n",
        "      for j in range(len(picks)):\n",
        "        distance_data.at[l, j] = str(sorted(picks[j]))\n",
        "\n",
        "    distance_data = (\n",
        "          distance_data.drop_duplicates()\n",
        "          .sort_values('distance')\n",
        "          .head(3)\n",
        "          .reset_index(drop=True)\n",
        "    )\n",
        "    return distance_data\n",
        "\n",
        "  @staticmethod\n",
        "  def _from_share(\n",
        "      dataframe,\n",
        "      target_share\n",
        "      ):\n",
        "    distance_data = pd.DataFrame(columns=['distance'])\n",
        "    combinations = []\n",
        "\n",
        "    n = CausalImpact.NUM_OF_ITERATION\n",
        "    while len(combinations) < CausalImpact.COMBINATION_TARGET:\n",
        "      n -= 1\n",
        "      picked_col = np.random.choice(\n",
        "          dataframe.columns,\n",
        "          # Shareは50%までなので列数を2分割\n",
        "          random.randint(1, len(dataframe.columns)//2 + 1),\n",
        "          replace=False)\n",
        "\n",
        "      # (todo)@rhirota シェアを除外済みか全体か検討\n",
        "      if float(Decimal(dataframe[picked_col].sum().sum() / dataframe.sum().sum()\n",
        "                      ).quantize(Decimal('0.1'), ROUND_HALF_UP)) == target_share:\n",
        "        combinations.append(sorted(set(picked_col)))\n",
        "      if n == 1:\n",
        "        PreProcess._apply_text_style('failure', '\\n\\nFailure!!')\n",
        "        print('Please check the following:')\n",
        "        print('* There is something wrong with design type C.')\n",
        "        print(\"* You couldn't find the right combination in the repetitions.\")\n",
        "        print('* Please re-try or re-set target share')\n",
        "        PreProcess._apply_text_style('failure', '▲▲▲▲▲▲\\n\\n')\n",
        "        raise Exception('Please check Failure')\n",
        "\n",
        "    for comb in tqdm(combinations):\n",
        "      for l in tqdm(\n",
        "          range(\n",
        "              CausalImpact.NUM_OF_ITERATION // CausalImpact.COMBINATION_TARGET),\n",
        "          leave=False):\n",
        "        picked_data = pd.DataFrame()\n",
        "        remained_list = [\n",
        "            i for i in list(dataframe.columns) if i not in comb\n",
        "        ]\n",
        "        picks = []\n",
        "        picks.append(random.sample(remained_list, random.randrange(\n",
        "            # (todo)@rhirota 最小Pickを検討\n",
        "            1, len(remained_list), 1\n",
        "            )\n",
        "        ))\n",
        "        picks.insert(0, comb)\n",
        "\n",
        "        for i in range(len(picks)):\n",
        "          picked_data = pd.concat([\n",
        "              picked_data,\n",
        "              pd.DataFrame(dataframe[picks[i]].sum(axis=1), columns=[i])\n",
        "              ], axis=1)\n",
        "\n",
        "      # calculate distance\n",
        "      distance = CausalImpact._calculate_distance(\n",
        "          picked_data.reset_index(drop=True)\n",
        "      )\n",
        "      distance_data.loc[l, 'distance'] = float(distance)\n",
        "      for j in range(len(picks)):\n",
        "        distance_data.at[l, j] = str(sorted(picks[j]))\n",
        "\n",
        "    distance_data = (\n",
        "          distance_data.drop_duplicates()\n",
        "          .sort_values('distance')\n",
        "          .head(3)\n",
        "          .reset_index(drop=True)\n",
        "    )\n",
        "    return distance_data\n",
        "\n",
        "  @staticmethod\n",
        "  def _given_assignment(target_columns, control_columns):\n",
        "    distance_data = pd.DataFrame(columns=['distance'])\n",
        "    distance_data.loc[0, 'distance'] = 0\n",
        "    distance_data.loc[0, 0] = str(target_columns.replace(', ', ',').split(','))\n",
        "    distance_data.loc[0, 1] = str(control_columns.replace(', ', ',').split(','))\n",
        "    return distance_data\n",
        "\n",
        "  @staticmethod\n",
        "  def _calculate_distance(dataframe):\n",
        "    total_distance = 0\n",
        "    scaled_data = pd.DataFrame()\n",
        "    for col in dataframe:\n",
        "      scaled_data[col] = (dataframe[col] - dataframe[col].min()) / (\n",
        "          dataframe[col].max() - dataframe[col].min()\n",
        "      )\n",
        "    scaled_data = scaled_data.diff().reset_index().dropna()\n",
        "    for v in itertools.combinations(list(scaled_data.columns), 2):\n",
        "      distance, _ = fastdtw.fastdtw(\n",
        "          scaled_data.loc[:, ['index', v[0]]],\n",
        "          scaled_data.loc[:, ['index', v[1]]],\n",
        "          dist=euclidean,\n",
        "      )\n",
        "      total_distance = total_distance + distance\n",
        "    return total_distance\n",
        "\n",
        "  @staticmethod\n",
        "  def _visualize_candidate(\n",
        "      dataframe,\n",
        "      distance_data,\n",
        "      start_date_value,\n",
        "      end_date_value,\n",
        "      date_col_name,\n",
        "      tick_count\n",
        "      ):\n",
        "    PreProcess._apply_text_style(\n",
        "          'failure',\n",
        "          '\\nCheck! Experimental Design Parameters.'\n",
        "          )\n",
        "    print('* start_date_value: ' + str(start_date_value))\n",
        "    print('* end_date_value: ' + str(end_date_value))\n",
        "    print('* columns:')\n",
        "    l = []\n",
        "    for i in range(len(dataframe.columns)):\n",
        "      l.append(dataframe.columns[i])\n",
        "      if len(str(l)) >= CausalImpact.MAX_STRING_LENGTH:\n",
        "        print(str(l).translate(str.maketrans({'[': '', ']': '',  \"'\": ''})))\n",
        "        l = []\n",
        "    print('\\n')\n",
        "\n",
        "    sub_tab=[ipywidgets.Output() for i in distance_data.index.tolist()]\n",
        "    tab_option = ipywidgets.Tab(sub_tab)\n",
        "    for i in range (len(distance_data.index.tolist())):\n",
        "        tab_option.set_title(i,\"option_{}\".format(i+1))\n",
        "        with sub_tab[i]:\n",
        "          candidate_df = pd.DataFrame(index=dataframe.index)\n",
        "          for col in range(len(distance_data.columns) - 1):\n",
        "            print(\n",
        "                'col_' + str(col + 1) + ': '+ distance_data.at[i, col].replace(\n",
        "                    \"'\", \"\"))\n",
        "            candidate_df[col + 1] = list(\n",
        "                dataframe.loc[:, eval(distance_data.at[i, col])].sum(axis=1)\n",
        "            )\n",
        "            print('\\n')\n",
        "          candidate_df = candidate_df.add_prefix('col_')\n",
        "\n",
        "          candidate_share = pd.DataFrame(\n",
        "              candidate_df.loc[str(start_date_value):str(end_date_value), :\n",
        "                               ].sum(),\n",
        "              columns=['total'])\n",
        "          candidate_share['daily_average'] = candidate_share['total'] // (\n",
        "              end_date_value - start_date_value).days\n",
        "          candidate_share['share'] = candidate_share['total'] / (dataframe.query(\n",
        "                '@start_date_value <= index <= @end_date_value'\n",
        "                ).sum().sum())\n",
        "\n",
        "          try:\n",
        "            for i in candidate_df.columns:\n",
        "              stl = STL(candidate_df[i], robust=True).fit()\n",
        "              candidate_share.loc[i, 'std'] = np.std(stl.seasonal + stl.resid)\n",
        "            display(\n",
        "                candidate_share[['daily_average', 'share', 'std']].style.format(\n",
        "                    {\n",
        "                        'daily_average': '{:,.0f}',\n",
        "                        'share': '{:.1%}',\n",
        "                        'std': '{:,.0f}',\n",
        "                        }))\n",
        "          except Exception as e:\n",
        "            print(e)\n",
        "            display(\n",
        "                candidate_share[['daily_average', 'share']].style.format({\n",
        "                'daily_average': '{:,.0f}',\n",
        "                'share': '{:.1%}',\n",
        "                }))\n",
        "\n",
        "          chart_line = (\n",
        "              alt.Chart(candidate_df.reset_index())\n",
        "              .transform_fold(\n",
        "                  fold=list(candidate_df.columns), as_=['pivot', 'kpi']\n",
        "              )\n",
        "              .mark_line()\n",
        "              .encode(\n",
        "                  x=alt.X(\n",
        "                      date_col_name + ':T',\n",
        "                      title=None,\n",
        "                      axis=alt.Axis(\n",
        "                      grid=False, format='%Y %b', tickCount=tick_count\n",
        "                      ),\n",
        "                  ),\n",
        "                  y=alt.Y('kpi:Q'),\n",
        "                  color=alt.Color(\n",
        "                    'pivot:N',\n",
        "                    legend=alt.Legend(\n",
        "                      title=None,\n",
        "                      orient='none',\n",
        "                      legendY=-20,\n",
        "                      direction='horizontal',\n",
        "                      titleAnchor='start'),\n",
        "                    scale=alt.Scale(\n",
        "                        domain=list(candidate_df.columns),\n",
        "                        range=CausalImpact.colors)),\n",
        "                  )\n",
        "              .properties(width=600, height=200)\n",
        "          )\n",
        "\n",
        "          rules = alt.Chart(\n",
        "              pd.DataFrame(\n",
        "                  {\n",
        "                      'Date': [str(start_date_value), str(end_date_value)],\n",
        "                      'color': ['red', 'orange']\n",
        "                      })\n",
        "              ).mark_rule(strokeDash=[5, 5]).encode(\n",
        "                  x='Date:T',\n",
        "                  color=alt.Color('color:N', scale=None))\n",
        "\n",
        "          df_scaled = candidate_df.copy()\n",
        "          df_scaled[:] = MinMaxScaler().fit_transform(candidate_df)\n",
        "          chart_line_scaled = (\n",
        "              alt.Chart(df_scaled.reset_index())\n",
        "              .transform_fold(\n",
        "                  fold=list(candidate_df.columns),\n",
        "                  as_=['pivot', 'kpi']\n",
        "              )\n",
        "              .mark_line()\n",
        "              .encode(\n",
        "                  x=alt.X(\n",
        "                      date_col_name + ':T',\n",
        "                      title=None,\n",
        "                      axis=alt.Axis(\n",
        "                      grid=False, format='%Y %b', tickCount=tick_count\n",
        "                      ),\n",
        "                  ),\n",
        "                  y=alt.Y('kpi:Q'),\n",
        "                  color=alt.Color(\n",
        "                    'pivot:N',\n",
        "                    legend=alt.Legend(\n",
        "                      title=None,\n",
        "                      orient='none',\n",
        "                      legendY=-20,\n",
        "                      direction='horizontal',\n",
        "                      titleAnchor='start'),\n",
        "                    scale=alt.Scale(\n",
        "                        domain=list(candidate_df.columns),\n",
        "                        range=CausalImpact.colors)),\n",
        "                  )\n",
        "              .properties(width=600, height=80)\n",
        "          )\n",
        "\n",
        "          df_diff = pd.DataFrame(\n",
        "              np.diff(candidate_df, axis=0),\n",
        "              columns=candidate_df.columns.values,\n",
        "          )\n",
        "          scatter = (\n",
        "              alt.Chart(df_diff.reset_index())\n",
        "              .mark_circle()\n",
        "              .encode(\n",
        "                  alt.X(alt.repeat('column'), type='quantitative'),\n",
        "                  alt.Y(alt.repeat('row'), type='quantitative'),\n",
        "              )\n",
        "              .properties(width=80, height=80)\n",
        "              .repeat(\n",
        "                  row=df_diff.columns.values,\n",
        "                  column=df_diff.columns.values,\n",
        "              )\n",
        "          )\n",
        "          display(\n",
        "              alt.vconcat(chart_line + rules, chart_line_scaled) | scatter)\n",
        "    display(tab_option)\n",
        "\n",
        "  def _generate_choice(self):\n",
        "    self.your_choice = ipywidgets.Dropdown(\n",
        "        options=['option_1', 'option_2', 'option_3'],\n",
        "        description='your choice:',\n",
        "    )\n",
        "    self.target_col_to_simulate = ipywidgets.SelectMultiple(\n",
        "        options=['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6'],\n",
        "        description='target col:',\n",
        "        value=['col_1',],\n",
        "    )\n",
        "    self.covariate_col_to_simulate = ipywidgets.SelectMultiple(\n",
        "        options=['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6'],\n",
        "        description='covatiate col:',\n",
        "        value=['col_2',],\n",
        "        style={'description_width': 'initial'},\n",
        "    )\n",
        "    display(\n",
        "        PreProcess._apply_text_style(\n",
        "            18,\n",
        "            '⑷ Please select option, test column & control column(s).'),\n",
        "        ipywidgets.HBox([\n",
        "            self.your_choice,\n",
        "            self.target_col_to_simulate,\n",
        "            self.covariate_col_to_simulate,\n",
        "        ]),\n",
        "    )\n",
        "\n",
        "  def generate_simulation(self):\n",
        "    self.test_data = self._extract_data_from_choice(\n",
        "        self.your_choice.value,\n",
        "        self.target_col_to_simulate.value,\n",
        "        self.covariate_col_to_simulate.value,\n",
        "        self.formatted_data,\n",
        "        self.distance_data,\n",
        "    )\n",
        "    self.simulation_params, self.ci_objs = self._execute_simulation(\n",
        "        self.test_data,\n",
        "        self.date_col_name,\n",
        "        self.start_date_value,\n",
        "        self.end_date_value,\n",
        "        self.num_of_seasons.value,\n",
        "        self.credible_interval.value,\n",
        "        CausalImpact.TREAT_DURATION,\n",
        "        CausalImpact.TREAT_IMPACT,\n",
        "    )\n",
        "    self._display_simulation_result(\n",
        "        self.simulation_params,\n",
        "        self.ci_objs,\n",
        "        self.estimate_icpa.value,\n",
        "    )\n",
        "    self._plot_simulation_result(\n",
        "        self.simulation_params,\n",
        "        self.ci_objs,\n",
        "        self.date_col_name,\n",
        "        self.tick_count,\n",
        "        self.purpose_selection.selected_index,\n",
        "        self.credible_interval.value,\n",
        "    )\n",
        "\n",
        "  @staticmethod\n",
        "  def _extract_data_from_choice(\n",
        "      your_choice,\n",
        "      target_col_to_simulate,\n",
        "      covariate_col_to_simulate,\n",
        "      dataframe,\n",
        "      distance\n",
        "      ):\n",
        "      selection_row = int(your_choice.replace('option_', '')) - 1\n",
        "      selection_cols = [\n",
        "          [int(t.replace('col_', '')) - 1 for t in list(target_col_to_simulate)],\n",
        "          [int(t.replace('col_', '')) - 1 for t in list(covariate_col_to_simulate)\n",
        "          ]]\n",
        "      test_data = pd.DataFrame(index = dataframe.index)\n",
        "\n",
        "      test_column = []\n",
        "      for i in selection_cols[0]:\n",
        "        test_column.extend(eval(distance.at[selection_row,i]))\n",
        "      test_data['test'] = dataframe.loc[\n",
        "                    :, test_column\n",
        "                ].sum(axis=1)\n",
        "\n",
        "      for col in selection_cols[1]:\n",
        "        test_data['col_'+ str(col+1)] = dataframe.loc[\n",
        "                :, eval(distance.at[selection_row, col])\n",
        "            ].sum(axis=1)\n",
        "\n",
        "      print('* test: {}\\n'.format(str(test_column).replace(\"'\", \"\")))\n",
        "      print('* covariate')\n",
        "      for x,i in zip(test_data.columns[1:],selection_cols[1]):\n",
        "        print('> {}: {}'.format(\n",
        "            x,\n",
        "            str(eval(distance.at[selection_row, i]))).replace(\"'\", \"\")\n",
        "            )\n",
        "      return test_data\n",
        "\n",
        "  @staticmethod\n",
        "  def _execute_simulation(\n",
        "      dataframe,\n",
        "      date_col_name,\n",
        "      start_date_value,\n",
        "      end_date_value,\n",
        "      num_of_seasons,\n",
        "      credible_interval,\n",
        "      TREAT_DURATION,\n",
        "      TREAT_IMPACT,\n",
        "    ):\n",
        "    ci_objs = []\n",
        "    simulation_params = []\n",
        "    adjusted_data = dataframe.copy()\n",
        "\n",
        "    for duration in tqdm(TREAT_DURATION):\n",
        "      for impact in tqdm(TREAT_IMPACT, leave=False):\n",
        "          pre_end_date = end_date_value + datetime.timedelta(days=-duration)\n",
        "          post_start_date = pre_end_date + datetime.timedelta(days=1)\n",
        "          adjusted_data.loc[\n",
        "              np.datetime64(post_start_date) : np.datetime64(end_date_value),\n",
        "              'test',] = (\n",
        "                  dataframe.loc[\n",
        "                  np.datetime64(post_start_date) : np.datetime64(end_date_value\n",
        "                  ),\n",
        "                  'test',\n",
        "              ]\n",
        "              * impact\n",
        "          )\n",
        "\n",
        "          ci_obj = CausalImpact.create_causalimpact_object(\n",
        "              adjusted_data,\n",
        "              date_col_name,\n",
        "              start_date_value,\n",
        "              pre_end_date,\n",
        "              post_start_date,\n",
        "              end_date_value,\n",
        "              num_of_seasons,\n",
        "              credible_interval,\n",
        "          )\n",
        "          simulation_params.append([\n",
        "              start_date_value,\n",
        "              pre_end_date,\n",
        "              post_start_date,\n",
        "              end_date_value,\n",
        "              impact,\n",
        "              duration,\n",
        "          ])\n",
        "          ci_objs.append(ci_obj)\n",
        "    return simulation_params, ci_objs\n",
        "\n",
        "  @staticmethod\n",
        "  def _display_simulation_result(simulation_params, ci_objs, estimate_icpa):\n",
        "      simulation_df = pd.DataFrame(\n",
        "          index=[],\n",
        "          columns=[\n",
        "              'mock_lift',\n",
        "              'Days_simulated',\n",
        "              'Pre_Period_MAPE',\n",
        "              'Post_Period_MAPE',\n",
        "              'Total_effect',\n",
        "              'Average_effect',\n",
        "              'Required_budget',\n",
        "              'p_value',\n",
        "              'predicted_lift'\n",
        "          ],\n",
        "      )\n",
        "      for i in range(len(ci_objs)):\n",
        "        impact_df = ci_objs[i].series\n",
        "        impact_dict = {\n",
        "            'test_period':'('+str(simulation_params[i][5])+'d) '+str(simulation_params[i][2])+'~'+str(simulation_params[i][3]),\n",
        "            'mock_lift_rate': simulation_params[i][4] - 1,\n",
        "            'predicted_lift_rate': ci_objs[i].summary.loc['average', 'rel_effect'],\n",
        "            'Days_simulated': simulation_params[i][5],\n",
        "            'Pre_Period_MAPE': [\n",
        "                mean_absolute_percentage_error(\n",
        "                    impact_df.loc[:, 'observed'][\n",
        "                        str(simulation_params[i][0]) : str(\n",
        "                            simulation_params[i][1]\n",
        "                        )\n",
        "                    ],\n",
        "                    impact_df.loc[:, 'posterior_mean'][\n",
        "                        str(simulation_params[i][0]) : str(\n",
        "                            simulation_params[i][1]\n",
        "                        )\n",
        "                    ],\n",
        "                )\n",
        "            ],\n",
        "            'Post_Period_MAPE': [\n",
        "                mean_absolute_percentage_error(\n",
        "                    impact_df.loc[:, 'observed'][\n",
        "                        str(simulation_params[i][2]) : str(\n",
        "                            simulation_params[i][3]\n",
        "                        )\n",
        "                    ],\n",
        "                    impact_df.loc[:, 'posterior_mean'][\n",
        "                        str(simulation_params[i][2]) : str(\n",
        "                            simulation_params[i][3]\n",
        "                        )\n",
        "                    ],\n",
        "                )\n",
        "            ],\n",
        "            'Total_effect': ci_objs[i].summary.loc['cumulative', 'abs_effect'],\n",
        "            'Average_effect': ci_objs[i].summary.loc['average', 'abs_effect'],\n",
        "            'Required_budget': [\n",
        "                ci_objs[i].summary.loc['cumulative', 'abs_effect'] * estimate_icpa\n",
        "            ],\n",
        "            'p_value': ci_objs[i].summary.loc['average', 'p_value'],\n",
        "\n",
        "        }\n",
        "        simulation_df = pd.concat(\n",
        "            [simulation_df, pd.DataFrame.from_dict(impact_dict)],\n",
        "            ignore_index=True,\n",
        "        )\n",
        "      display(PreProcess._apply_text_style(\n",
        "            18,\n",
        "            'A/A Test: Check the error without intervention'))\n",
        "      print('> If p_value < 0.05, please suspect \"poor model accuracy\"(See Pre_Period_MAPE) or \"data drift\"(See Time Series Chart).\\n')\n",
        "      display(\n",
        "          simulation_df.query('mock_lift_rate == 0')[\n",
        "              ['test_period','Pre_Period_MAPE','Post_Period_MAPE','p_value']\n",
        "              ].style.format({\n",
        "                  'Pre_Period_MAPE': '{:.2%}',\n",
        "                  'Post_Period_MAPE': '{:.2%}',\n",
        "                  'p_value': '{:,.2f}',\n",
        "                  }).hide()\n",
        "              )\n",
        "      print('\\n')\n",
        "      display(PreProcess._apply_text_style(\n",
        "            18,\n",
        "            'Simulation with increments as a mock experiment'))\n",
        "      for i in simulation_df.Days_simulated.unique():\n",
        "        print('\\n During the last {} days'.format(i))\n",
        "        display(\n",
        "            simulation_df.query('mock_lift_rate != 0 & Days_simulated == @i')[\n",
        "                [\n",
        "                    'mock_lift_rate',\n",
        "                    'predicted_lift_rate',\n",
        "                    'Pre_Period_MAPE',\n",
        "                    'Total_effect',\n",
        "                    'Average_effect',\n",
        "                    'Required_budget',\n",
        "                    'p_value',\n",
        "                    ]\n",
        "            ].style.format({\n",
        "                'mock_lift_rate': '{:+.0%}',\n",
        "                'predicted_lift_rate': '{:+.1%}',\n",
        "                'Pre_Period_MAPE': '{:.2%}',\n",
        "                'Total_effect': '{:,.2f}',\n",
        "                'Average_effect': '{:,.2f}',\n",
        "                'Required_budget': '{:,.0f}',\n",
        "                'p_value': '{:,.2f}',\n",
        "            }).hide()\n",
        "        )\n",
        "\n",
        "  @staticmethod\n",
        "  def _plot_simulation_result(\n",
        "      simulation_params,\n",
        "      ci_objs,\n",
        "      date_col_name,\n",
        "      tick_count,\n",
        "      purpose_selection,\n",
        "      credible_interval,\n",
        "      ):\n",
        "\n",
        "    mock_combinations = []\n",
        "    for i in range(len(simulation_params)):\n",
        "      mock_combinations.append(\n",
        "            [\n",
        "                '{}d:+{:.0%}'.format(\n",
        "                    simulation_params[i][5],\n",
        "                    simulation_params[i][4]-1)\n",
        "            ])\n",
        "    simulation_tb=[ipywidgets.Output() for tab in mock_combinations]\n",
        "    tab_simulation = ipywidgets.Tab(simulation_tb)\n",
        "    for id,name in enumerate(mock_combinations):\n",
        "      tab_simulation.set_title(id,name)\n",
        "      with simulation_tb[id]:\n",
        "        print(\n",
        "            'Pre Period:{} ~ {}\\nPost Period:{} ~ {}'.format(\n",
        "                simulation_params[id][0],\n",
        "                simulation_params[id][1],\n",
        "                simulation_params[id][2],\n",
        "                simulation_params[id][3],\n",
        "            )\n",
        "        )\n",
        "        CausalImpact.plot_causalimpact(\n",
        "            ci_objs[id],\n",
        "            simulation_params[id][0],\n",
        "            simulation_params[id][1],\n",
        "            simulation_params[id][2],\n",
        "            simulation_params[id][3],\n",
        "            credible_interval,\n",
        "            date_col_name,\n",
        "            tick_count,\n",
        "            purpose_selection\n",
        "        )\n",
        "    display(tab_simulation)\n",
        "\n",
        "case_1 = CausalImpact()\n",
        "case_1.generate_ui()\n",
        "if 'dict_params' in globals():\n",
        "  CausalImpact.set_params(case_1, dict_params)\n",
        "print('\\nExecution datetime(GMT):{}'.format(datetime.datetime.now()))\n"
      ],
      "metadata": {
        "id": "_WR_6zEwE2yK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step.2\n",
        "%%time\n",
        "case_1.load_data()\n",
        "case_1.format_data()\n",
        "dict_params = PreProcess.saving_params(case_1)\n",
        "\n",
        "if case_1.purpose_selection.selected_index == 0:\n",
        "  case_1.run_causalImpact()\n",
        "else:\n",
        "  case_1.run_experimental_design()\n",
        "\n",
        "print('\\nExecution datetime(GMT):{}'.format(datetime.datetime.now()))"
      ],
      "metadata": {
        "id": "c94KKPvvlB3u",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step.3\n",
        "%%time\n",
        "if case_1.purpose_selection.selected_index == 0:\n",
        "  case_1.display_causalimpact_result()\n",
        "else:\n",
        "  case_1.generate_simulation()\n",
        "\n",
        "print('\\nExecution datetime(GMT):{}'.format(datetime.datetime.now()))"
      ],
      "metadata": {
        "id": "yK5gZ0KioPP4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Optional) Case_2"
      ],
      "metadata": {
        "id": "yRkmseYMdtfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Case_2 Step.1\n",
        "overwrite_pramas = True #@param {type:\"boolean\"}\n",
        "case_2 = CausalImpact()\n",
        "case_2.generate_ui()\n",
        "if overwrite_pramas == True: PreProcess.set_params(case_2, dict_params)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PsQlufVpdxOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Case_2 Step.2\n",
        "%%time\n",
        "case_2.load_data()\n",
        "case_2.format_data()\n",
        "\n",
        "if case_2.purpose_selection.selected_index == 0:\n",
        "  case_2.run_causalImpact()\n",
        "else:\n",
        "  case_2.run_experimental_design()\n",
        "\n",
        "print('\\nExecution datetime(GMT):{}'.format(datetime.datetime.now()))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rMgpKut9ewEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Case_2 Step.3\n",
        "%%time\n",
        "if case_2.purpose_selection.selected_index == 0:\n",
        "  case_2.display_causalimpact_result()\n",
        "else:\n",
        "  case_2.generate_simulation()\n",
        "\n",
        "print('\\nExecution datetime(GMT):{}'.format(datetime.datetime.now()))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L7H9OEhme7Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Optional) Case_3"
      ],
      "metadata": {
        "id": "wyh14BKUfKcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Case_3 Step.1\n",
        "overwrite_pramas = False #@param {type:\"boolean\"}\n",
        "case_3 = CausalImpact()\n",
        "case_3.generate_ui()\n",
        "if overwrite_pramas == True: PreProcess.set_params(case_3, dict_params)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Gb_PkbFifKcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Case_3 Step.2\n",
        "%%time\n",
        "case_3.load_data()\n",
        "case_3.format_data()\n",
        "\n",
        "if case_3.purpose_selection.selected_index == 0:\n",
        "  case_3.run_causalImpact()\n",
        "else:\n",
        "  case_3.run_experimental_design()\n",
        "\n",
        "print('\\nExecution datetime(GMT):{}'.format(datetime.datetime.now()))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UUKm41oWfKcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Case_3 Step.3\n",
        "%%time\n",
        "if case_3.purpose_selection.selected_index == 0:\n",
        "  case_3.display_causalimpact_result()\n",
        "else:\n",
        "  case_3.generate_simulation()\n",
        "\n",
        "print('\\nExecution datetime(GMT):{}'.format(datetime.datetime.now()))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7Ssv3wP9fKcF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}